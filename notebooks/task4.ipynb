{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02be532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TASK 4 - FIXED PROXY TARGET VARIABLE ENGINEERING\n",
      "Using Business Rules Based on EDA Insights\n",
      "======================================================================\n",
      "Loaded 95,662 transactions for 3,742 customers\n",
      "Data range: 2018-11-15 02:18:49+00:00 to 2019-02-13 10:01:28+00:00\n",
      "\n",
      "1. CALCULATING CUSTOMER FEATURES\n",
      "----------------------------------------\n",
      "Created 3742 customer profiles with 14 features\n",
      "\n",
      "2. DEFINING BUSINESS RULES FOR HIGH-RISK\n",
      "----------------------------------------\n",
      "Based on EDA Insights:\n",
      "1. ChannelId_1 has 3.7Ã— higher fraud rate\n",
      "2. Negative total amount indicates more refunds than purchases\n",
      "3. Low frequency (< 1 transaction per week) indicates disengagement\n",
      "4. High proportion of transactions during high-fraud hours (9PM-3AM)\n",
      "5. High transaction amount variability (unstable spending)\n",
      "  Rule 1 (ChannelId_1 users): 92 customers\n",
      "  Rule 2 (Negative total): 192 customers\n",
      "  Rule 3 (Low frequency): 71 customers\n",
      "  Rule 4 (High fraud hour ratio): 904 customers\n",
      "  Rule 5 (High variability): 2797 customers\n",
      "  Rule 6 (Fraud history): 54 customers\n",
      "\n",
      "Applied 6 business rules to identify high-risk customers\n",
      "\n",
      "3. ANALYZING RISK DISTRIBUTION\n",
      "----------------------------------------\n",
      "Risk distribution:\n",
      "  Low Risk: 617 customers (16.5%)\n",
      "  High Risk: 3,125 customers (83.5%)\n",
      "\n",
      "Number of customers triggering each rule:\n",
      "  Uses ChannelId_1              :    92 (2.5%)\n",
      "  Negative total amount         :   192 (5.1%)\n",
      "  Low frequency (<1/week)       :    71 (1.9%)\n",
      "  High fraud hour ratio (>30%)  :   904 (24.2%)\n",
      "  High variability (CV>50%)     :  2797 (74.7%)\n",
      "  Has fraud history             :    54 (1.4%)\n",
      "\n",
      "4. CHARACTERISTICS OF HIGH-RISK CUSTOMERS\n",
      "----------------------------------------\n",
      "\n",
      "Comparing high-risk vs low-risk customers:\n",
      "Metric                                Low Risk       High Risk     Diff %\n",
      "--------------------------------------------------------------------------------\n",
      "transaction_count                         1.45           30.33     1993.0%\n",
      "total_amount                          23252.76       201054.62      764.6%\n",
      "avg_amount                            19980.09        14873.64      -25.6%\n",
      "recency_days                             46.41           28.11      -39.4%\n",
      "frequency_per_day                         1.31            3.01      129.5%\n",
      "high_fraud_hour_ratio                     0.00            0.25    36665.5%\n",
      "amount_cv                                 0.03            5.44    19216.6%\n",
      "\n",
      "5. PREPARING DATA FOR MODEL TRAINING\n",
      "----------------------------------------\n",
      "Model data shape: (3742, 12)\n",
      "Features: transaction_count, total_amount, avg_amount, amount_std, recency_days...\n",
      "Target: is_high_risk (1 = high risk, 0 = low risk)\n",
      "\n",
      "Class distribution:\n",
      "  High Risk: 83.5%\n",
      "  Low Risk: 16.5%\n",
      "\n",
      "6. SAVING RESULTS\n",
      "----------------------------------------\n",
      "âœ“ Saved to data/processed/customers_with_proxy_target_fixed.csv\n",
      "âœ“ Saved target to data/processed/proxy_target_fixed.csv\n",
      "âœ“ Saved feature list to data/processed/model_features_fixed.txt\n",
      "âœ“ Saved feature statistics to data/processed/feature_statistics.csv\n",
      "âœ“ Saved risk comparison data to data/processed/risk_comparison.csv\n",
      "\n",
      "======================================================================\n",
      "PROXY TARGET ENGINEERING COMPLETE - SUMMARY\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š RISK DISTRIBUTION\n",
      "   Total customers: 3,742\n",
      "   Low risk: 617 (16.5%)\n",
      "   High risk: 3,125 (83.5%)\n",
      "\n",
      "ðŸ“ˆ CLASS BALANCE\n",
      "   Ratio (High:Low): 1:0.2\n",
      "   âš  Class imbalance - consider sampling techniques during training\n",
      "\n",
      "ðŸ”§ BUSINESS RULES APPLIED\n",
      "   1. Uses ChannelId_1 (high-risk channel)\n",
      "   2. Has negative total amount\n",
      "   3. Frequency < 1 transaction/week\n",
      "   4. >30% transactions in high-fraud hours (9PM-3AM local time)\n",
      "   5. High transaction variability (CV > 50%)\n",
      "   6. Any fraud history\n",
      "\n",
      "ðŸŽ¯ FEATURES FOR MODELING\n",
      "   Number of features: 10\n",
      "   Key behavioral features:\n",
      "     â€¢ Frequency: transaction_count, frequency_per_day\n",
      "     â€¢ Monetary: total_amount, avg_amount\n",
      "     â€¢ Recency: recency_days, customer_tenure_days\n",
      "     â€¢ Risk indicators: high_risk_channel_use, high_fraud_hour_ratio, amount_cv\n",
      "\n",
      "ðŸ’¾ OUTPUT FILES\n",
      "   âœ“ data/processed/customers_with_proxy_target_fixed.csv\n",
      "     Complete dataset for modeling (CustomerId + features + target)\n",
      "   âœ“ data/processed/proxy_target_fixed.csv\n",
      "     Target variable only (CustomerId + is_high_risk)\n",
      "   âœ“ data/processed/model_features_fixed.txt\n",
      "     List of features for modeling\n",
      "   âœ“ data/processed/feature_statistics.csv\n",
      "     Feature descriptive statistics\n",
      "   âœ“ data/processed/risk_comparison.csv\n",
      "     High-risk vs low-risk comparison\n",
      "\n",
      "======================================================================\n",
      "READY FOR TASK 5 - MODEL TRAINING\n",
      "======================================================================\n",
      "\n",
      "Next steps:\n",
      "   1. Load 'customers_with_proxy_target_fixed.csv'\n",
      "   2. Split into train/test sets (80/20)\n",
      "   3. Train at least 2 models (e.g., Logistic Regression, Random Forest)\n",
      "   4. Hyperparameter tuning with GridSearchCV\n",
      "   5. Evaluate using: Accuracy, Precision, Recall, F1, ROC-AUC\n",
      "   6. Track experiments with MLflow\n",
      "\n",
      "Example code for Task 5:\n",
      "   import pandas as pd\n",
      "   from sklearn.model_selection import train_test_split\n",
      "   \n",
      "   data = pd.read_csv('data/processed/customers_with_proxy_target_fixed.csv')\n",
      "   X = data.drop(['CustomerId', 'is_high_risk'], axis=1)\n",
      "   y = data['is_high_risk']\n",
      "   \n",
      "   X_train, X_test, y_train, y_test = train_test_split(\n",
      "       X, y, test_size=0.2, random_state=42, stratify=y\n",
      "   )\n",
      "\n",
      "âœ… Task 4 is now complete and ready for model training!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Task 4 - FIXED Proxy Target Variable Engineering\n",
    "Using business rules instead of K-Means clustering - ALL BUGS FIXED\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TASK 4 - FIXED PROXY TARGET VARIABLE ENGINEERING\")\n",
    "print(\"Using Business Rules Based on EDA Insights\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load the data (same as EDA)\n",
    "df = pd.read_csv(\"../data/raw/data.csv\")\n",
    "df[\"TransactionStartTime\"] = pd.to_datetime(df[\"TransactionStartTime\"], utc=True)\n",
    "\n",
    "print(f\"Loaded {len(df):,} transactions for {df['CustomerId'].nunique():,} customers\")\n",
    "print(f\"Data range: {df['TransactionStartTime'].min()} to {df['TransactionStartTime'].max()}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Calculate Customer-Level Features\n",
    "# -----------------------------\n",
    "print(\"\\n1. CALCULATING CUSTOMER FEATURES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create customer-level features\n",
    "customer_features = df.groupby('CustomerId').agg({\n",
    "    'TransactionId': 'count',  # Frequency\n",
    "    'Amount': ['sum', 'mean', 'std'],  # Monetary\n",
    "    'Value': 'sum',\n",
    "    'FraudResult': 'sum',\n",
    "    'ChannelId': lambda x: (x == 'ChannelId_1').sum(),  # High-risk channel usage\n",
    "    'TransactionStartTime': ['min', 'max']  # For recency\n",
    "}).reset_index()\n",
    "\n",
    "customer_features.columns = [\n",
    "    'CustomerId', 'transaction_count', 'total_amount', 'avg_amount', \n",
    "    'amount_std', 'total_value', 'fraud_count', 'high_risk_channel_use',\n",
    "    'first_transaction', 'last_transaction'\n",
    "]\n",
    "\n",
    "# Convert to timezone-naive for easier calculations\n",
    "customer_features['first_transaction'] = customer_features['first_transaction'].dt.tz_localize(None)\n",
    "customer_features['last_transaction'] = customer_features['last_transaction'].dt.tz_localize(None)\n",
    "\n",
    "# Calculate additional features - FIXED TIMEZONE ISSUE\n",
    "# Use the max date from data as snapshot date\n",
    "snapshot_date = pd.Timestamp('2019-02-14')  # Based on EDA max date\n",
    "customer_features['recency_days'] = (snapshot_date - customer_features['last_transaction']).dt.days\n",
    "customer_features['customer_tenure_days'] = (customer_features['last_transaction'] - customer_features['first_transaction']).dt.days\n",
    "customer_features['frequency_per_day'] = customer_features['transaction_count'] / np.maximum(customer_features['customer_tenure_days'], 1)\n",
    "\n",
    "# Calculate transaction during high-fraud hours (9PM-3AM)\n",
    "# Convert to local time if needed (assuming UTC, convert to East Africa Time = UTC+3)\n",
    "df['hour_local'] = (df['TransactionStartTime'] + pd.Timedelta(hours=3)).dt.hour\n",
    "df['high_fraud_hour'] = ((df['hour_local'] >= 21) | (df['hour_local'] <= 3)).astype(int)\n",
    "\n",
    "high_fraud_txns = df.groupby('CustomerId')['high_fraud_hour'].mean().reset_index()\n",
    "high_fraud_txns.columns = ['CustomerId', 'high_fraud_hour_ratio']\n",
    "\n",
    "customer_features = customer_features.merge(high_fraud_txns, on='CustomerId', how='left')\n",
    "customer_features['high_fraud_hour_ratio'] = customer_features['high_fraud_hour_ratio'].fillna(0)\n",
    "\n",
    "print(f\"Created {len(customer_features)} customer profiles with {len(customer_features.columns)} features\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Define Business Rules for High-Risk Classification\n",
    "# -----------------------------\n",
    "print(\"\\n2. DEFINING BUSINESS RULES FOR HIGH-RISK\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"Based on EDA Insights:\")\n",
    "print(\"1. ChannelId_1 has 3.7Ã— higher fraud rate\")\n",
    "print(\"2. Negative total amount indicates more refunds than purchases\")\n",
    "print(\"3. Low frequency (< 1 transaction per week) indicates disengagement\")\n",
    "print(\"4. High proportion of transactions during high-fraud hours (9PM-3AM)\")\n",
    "print(\"5. High transaction amount variability (unstable spending)\")\n",
    "\n",
    "# Define thresholds\n",
    "customer_features['is_high_risk'] = 0  # Default to low risk\n",
    "\n",
    "# Calculate coefficient of variation safely\n",
    "customer_features['amount_std_filled'] = customer_features['amount_std'].fillna(0)\n",
    "customer_features['avg_amount_abs'] = np.abs(customer_features['avg_amount']).replace(0, 1)\n",
    "customer_features['amount_cv'] = customer_features['amount_std_filled'] / customer_features['avg_amount_abs']\n",
    "\n",
    "# Rule 1: Uses high-risk channel (ChannelId_1)\n",
    "customer_features.loc[customer_features['high_risk_channel_use'] > 0, 'is_high_risk'] = 1\n",
    "print(f\"  Rule 1 (ChannelId_1 users): {len(customer_features[customer_features['high_risk_channel_use'] > 0])} customers\")\n",
    "\n",
    "# Rule 2: Has negative total amount (more refunds than purchases)\n",
    "customer_features.loc[customer_features['total_amount'] < 0, 'is_high_risk'] = 1\n",
    "print(f\"  Rule 2 (Negative total): {len(customer_features[customer_features['total_amount'] < 0])} customers\")\n",
    "\n",
    "# Rule 3: Low frequency (less than 1 transaction per week)\n",
    "customer_features.loc[customer_features['frequency_per_day'] < 1/7, 'is_high_risk'] = 1\n",
    "print(f\"  Rule 3 (Low frequency): {len(customer_features[customer_features['frequency_per_day'] < 1/7])} customers\")\n",
    "\n",
    "# Rule 4: High proportion of transactions during high-fraud hours\n",
    "customer_features.loc[customer_features['high_fraud_hour_ratio'] > 0.3, 'is_high_risk'] = 1  # Lowered to 30%\n",
    "print(f\"  Rule 4 (High fraud hour ratio): {len(customer_features[customer_features['high_fraud_hour_ratio'] > 0.3])} customers\")\n",
    "\n",
    "# Rule 5: High transaction variability (more than 50% CV)\n",
    "customer_features.loc[customer_features['amount_cv'] > 0.5, 'is_high_risk'] = 1\n",
    "print(f\"  Rule 5 (High variability): {len(customer_features[customer_features['amount_cv'] > 0.5])} customers\")\n",
    "\n",
    "# Optional: Has any fraud history\n",
    "customer_features.loc[customer_features['fraud_count'] > 0, 'is_high_risk'] = 1\n",
    "print(f\"  Rule 6 (Fraud history): {len(customer_features[customer_features['fraud_count'] > 0])} customers\")\n",
    "\n",
    "print(\"\\nApplied 6 business rules to identify high-risk customers\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Analyze Results\n",
    "# -----------------------------\n",
    "print(\"\\n3. ANALYZING RISK DISTRIBUTION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "risk_counts = customer_features['is_high_risk'].value_counts()\n",
    "risk_percentage = risk_counts / len(customer_features) * 100\n",
    "\n",
    "print(f\"Risk distribution:\")\n",
    "print(f\"  Low Risk: {risk_counts.get(0, 0):,} customers ({risk_percentage.get(0, 0):.1f}%)\")\n",
    "print(f\"  High Risk: {risk_counts.get(1, 0):,} customers ({risk_percentage.get(1, 0):.1f}%)\")\n",
    "\n",
    "# Check which rules triggered most (excluding those already marked high risk by previous rules)\n",
    "print(f\"\\nNumber of customers triggering each rule:\")\n",
    "rules_summary = {\n",
    "    'Uses ChannelId_1': (customer_features['high_risk_channel_use'] > 0).sum(),\n",
    "    'Negative total amount': (customer_features['total_amount'] < 0).sum(),\n",
    "    'Low frequency (<1/week)': (customer_features['frequency_per_day'] < 1/7).sum(),\n",
    "    'High fraud hour ratio (>30%)': (customer_features['high_fraud_hour_ratio'] > 0.3).sum(),\n",
    "    'High variability (CV>50%)': (customer_features['amount_cv'] > 0.5).sum(),\n",
    "    'Has fraud history': (customer_features['fraud_count'] > 0).sum()\n",
    "}\n",
    "\n",
    "for rule, count in rules_summary.items():\n",
    "    print(f\"  {rule:30}: {count:5d} ({count/len(customer_features)*100:.1f}%)\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Visualize High-Risk Characteristics\n",
    "# -----------------------------\n",
    "print(\"\\n4. CHARACTERISTICS OF HIGH-RISK CUSTOMERS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "low_risk = customer_features[customer_features['is_high_risk'] == 0]\n",
    "high_risk = customer_features[customer_features['is_high_risk'] == 1]\n",
    "\n",
    "print(f\"\\nComparing high-risk vs low-risk customers:\")\n",
    "print(f\"{'Metric':30} {'Low Risk':>15} {'High Risk':>15} {'Diff %':>10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "comparison_data = []\n",
    "for col in ['transaction_count', 'total_amount', 'avg_amount', 'recency_days', \n",
    "            'frequency_per_day', 'high_fraud_hour_ratio', 'amount_cv']:\n",
    "    if col in customer_features.columns:\n",
    "        low_mean = low_risk[col].mean()\n",
    "        high_mean = high_risk[col].mean()\n",
    "        \n",
    "        # FIXED: Handle division by zero properly\n",
    "        if abs(low_mean) < 0.0001:  # Near zero\n",
    "            diff_pct = 100 if high_mean > 0 else -100 if high_mean < 0 else 0\n",
    "        else:\n",
    "            diff_pct = ((high_mean - low_mean) / abs(low_mean)) * 100\n",
    "        \n",
    "        print(f\"{col:30} {low_mean:15.2f} {high_mean:15.2f} {diff_pct:10.1f}%\")\n",
    "        comparison_data.append({\n",
    "            'metric': col,\n",
    "            'low_risk': low_mean,\n",
    "            'high_risk': high_mean,\n",
    "            'diff_pct': diff_pct\n",
    "        })\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Prepare for Model Training\n",
    "# -----------------------------\n",
    "print(\"\\n5. PREPARING DATA FOR MODEL TRAINING\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Select features for modeling\n",
    "feature_columns = [\n",
    "    'transaction_count', 'total_amount', 'avg_amount', 'amount_std',\n",
    "    'recency_days', 'customer_tenure_days', 'frequency_per_day',\n",
    "    'high_risk_channel_use', 'high_fraud_hour_ratio', 'amount_cv'\n",
    "]\n",
    "\n",
    "# Create model-ready dataset\n",
    "model_data = customer_features[['CustomerId', 'is_high_risk'] + feature_columns].copy()\n",
    "\n",
    "# Handle missing values\n",
    "for col in feature_columns:\n",
    "    if model_data[col].isnull().any():\n",
    "        model_data[col] = model_data[col].fillna(model_data[col].median())\n",
    "\n",
    "print(f\"Model data shape: {model_data.shape}\")\n",
    "print(f\"Features: {', '.join(feature_columns[:5])}...\")\n",
    "print(f\"Target: is_high_risk (1 = high risk, 0 = low risk)\")\n",
    "\n",
    "# Check class distribution\n",
    "class_dist = model_data['is_high_risk'].value_counts(normalize=True)\n",
    "print(f\"\\nClass distribution:\")\n",
    "for risk_class, percentage in class_dist.items():\n",
    "    label = \"High Risk\" if risk_class == 1 else \"Low Risk\"\n",
    "    print(f\"  {label}: {percentage:.1%}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Save Results\n",
    "# -----------------------------\n",
    "print(\"\\n6. SAVING RESULTS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "# Save processed data\n",
    "output_path = 'data/processed/customers_with_proxy_target_fixed.csv'\n",
    "model_data.to_csv(output_path, index=False)\n",
    "print(f\"âœ“ Saved to {output_path}\")\n",
    "\n",
    "# Save target separately\n",
    "target_path = 'data/processed/proxy_target_fixed.csv'\n",
    "model_data[['CustomerId', 'is_high_risk']].to_csv(target_path, index=False)\n",
    "print(f\"âœ“ Saved target to {target_path}\")\n",
    "\n",
    "# Save feature list\n",
    "features_path = 'data/processed/model_features_fixed.txt'\n",
    "with open(features_path, 'w') as f:\n",
    "    for feature in feature_columns:\n",
    "        f.write(f\"{feature}\\n\")\n",
    "print(f\"âœ“ Saved feature list to {features_path}\")\n",
    "\n",
    "# Save descriptive statistics\n",
    "stats_path = 'data/processed/feature_statistics.csv'\n",
    "stats_df = model_data[feature_columns].describe().T\n",
    "stats_df.to_csv(stats_path)\n",
    "print(f\"âœ“ Saved feature statistics to {stats_path}\")\n",
    "\n",
    "# Save comparison data\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_path = 'data/processed/risk_comparison.csv'\n",
    "comparison_df.to_csv(comparison_path, index=False)\n",
    "print(f\"âœ“ Saved risk comparison data to {comparison_path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Summary Report\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PROXY TARGET ENGINEERING COMPLETE - SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nðŸ“Š RISK DISTRIBUTION\")\n",
    "print(f\"   Total customers: {len(model_data):,}\")\n",
    "print(f\"   Low risk: {risk_counts.get(0, 0):,} ({risk_percentage.get(0, 0):.1f}%)\")\n",
    "print(f\"   High risk: {risk_counts.get(1, 0):,} ({risk_percentage.get(1, 0):.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ CLASS BALANCE\")\n",
    "imbalance_ratio = risk_counts.get(1, 0) / risk_counts.get(0, 0) if risk_counts.get(0, 0) > 0 else 1\n",
    "print(f\"   Ratio (High:Low): 1:{1/imbalance_ratio:.1f}\")\n",
    "if 0.25 <= imbalance_ratio <= 0.75:\n",
    "    print(f\"   âœ… Good class balance for modeling\")\n",
    "else:\n",
    "    print(f\"   âš  Class imbalance - consider sampling techniques during training\")\n",
    "\n",
    "print(f\"\\nðŸ”§ BUSINESS RULES APPLIED\")\n",
    "rules_list = [\n",
    "    \"Uses ChannelId_1 (high-risk channel)\",\n",
    "    \"Has negative total amount\",\n",
    "    \"Frequency < 1 transaction/week\",\n",
    "    \">30% transactions in high-fraud hours (9PM-3AM local time)\",\n",
    "    \"High transaction variability (CV > 50%)\",\n",
    "    \"Any fraud history\"\n",
    "]\n",
    "for i, rule in enumerate(rules_list, 1):\n",
    "    print(f\"   {i}. {rule}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ FEATURES FOR MODELING\")\n",
    "print(f\"   Number of features: {len(feature_columns)}\")\n",
    "print(f\"   Key behavioral features:\")\n",
    "print(f\"     â€¢ Frequency: transaction_count, frequency_per_day\")\n",
    "print(f\"     â€¢ Monetary: total_amount, avg_amount\")\n",
    "print(f\"     â€¢ Recency: recency_days, customer_tenure_days\")\n",
    "print(f\"     â€¢ Risk indicators: high_risk_channel_use, high_fraud_hour_ratio, amount_cv\")\n",
    "\n",
    "print(f\"\\nðŸ’¾ OUTPUT FILES\")\n",
    "files = [\n",
    "    (output_path, \"Complete dataset for modeling (CustomerId + features + target)\"),\n",
    "    (target_path, \"Target variable only (CustomerId + is_high_risk)\"),\n",
    "    (features_path, \"List of features for modeling\"),\n",
    "    (stats_path, \"Feature descriptive statistics\"),\n",
    "    (comparison_path, \"High-risk vs low-risk comparison\")\n",
    "]\n",
    "for path, desc in files:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"   âœ“ {path}\")\n",
    "        print(f\"     {desc}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"READY FOR TASK 5 - MODEL TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"   1. Load 'customers_with_proxy_target_fixed.csv'\")\n",
    "print(f\"   2. Split into train/test sets (80/20)\")\n",
    "print(f\"   3. Train at least 2 models (e.g., Logistic Regression, Random Forest)\")\n",
    "print(f\"   4. Hyperparameter tuning with GridSearchCV\")\n",
    "print(f\"   5. Evaluate using: Accuracy, Precision, Recall, F1, ROC-AUC\")\n",
    "print(f\"   6. Track experiments with MLflow\")\n",
    "print(f\"\\nExample code for Task 5:\")\n",
    "print(f\"   import pandas as pd\")\n",
    "print(f\"   from sklearn.model_selection import train_test_split\")\n",
    "print(f\"   \")\n",
    "print(f\"   data = pd.read_csv('data/processed/customers_with_proxy_target_fixed.csv')\")\n",
    "print(f\"   X = data.drop(['CustomerId', 'is_high_risk'], axis=1)\")\n",
    "print(f\"   y = data['is_high_risk']\")\n",
    "print(f\"   \")\n",
    "print(f\"   X_train, X_test, y_train, y_test = train_test_split(\")\n",
    "print(f\"       X, y, test_size=0.2, random_state=42, stratify=y\")\n",
    "print(f\"   )\")\n",
    "\n",
    "print(f\"\\nâœ… Task 4 is now complete and ready for model training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626c8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
